---
layout: post
title: "How to get a job in data science"
description: 
categories: "blog"
published: false
---

It is said that if you give the same advice more than three times, you should write it down in a blog post. I've been approached many times for advice from job-seekers in the field of data science, so this is that blog post.

Imagine you are looking to hire a data scientist. You open up your applicant tracking system and read the most recent application for the job you posted three days ago. The person has a promising profile:

- Bachelor's degree with a double-major in computer science and economics.
- Master's degree in economics.
- One year of part-time consulting in data mining and analytics.

However, you already have a shortlist of 20 candidates to be considered for a phone screen. You've read through 120 applications in the past three days, and many of them looked just as promising as this one. In all likelihood, you won't return to this applicant's profile. For all you know, this person is all talk. Anyone can put the words "data mining" on a resume.

You go to the top of your shortlist. This person has a similarly promising profile:

- Bachelor's degree in mechanical engineering.
- Professional master's in data science.
- One year of experience as a data scientist, with a special interest in deep learning for NLP.

By their profile alone, this person is no more promising than the other. But this person is at the top of your shortlist, while the other person is already forgotten. Why? Two reasons.

1. This person linked to their [blog](<https://opringle.github.io/>), where they demonstrated their skills by writing tutorials on implementing state-of-the-art deep learning models for sentence classification.
2. This person came recommended by one of your current employees.

The basic model of hiring is that when a company hires someone, they want to be as confident as possible that the person 1) *can* and 2) *will* do the job. Most people's resumes do extremely little on their own to inspire this confidence, especially in a tough job market. But publicly viewable work and referrals each do their part quite well. A blog post or side project can provide plenty of positive evidence of a candidate's skill: whether they *can* do the job. A referral provides positive evidence of their character: whether they *will* do the job.

Your challenge, then, is to create patent evidence of those two qualities—your skills and your character—and then bring it to the attention of the team you want to work on.

The best way to create evidence of your skills is to use them and then share the artifacts of your work. This doesn't have to be a public thing. You can do a project that is targeted directly at the company you want to work for. Read the job posting carefully to figure out what the responsibilities are, and then spend a weekend putting together a small project that demonstrates your ability to fulfill those responsibilities. 

If you're lucky, the job posting will include details about a take-home assessment that will be required as part of the interview process. 99% of people who apply to the position will just submit a resume and a boiler-plate cover letter; they wouldn't dream of doing the take-home assessment before even getting a first interview. So a great way to stand out is to do the project preemptively and send it in. Even if nothing comes of it, you're likely to learn something valuable in the process. Besides, as long as there are no confidentiality issues, you can always share that project when applying to other companies. The important thing is that you've created evidence of your skills.

You might worry—what if you *can't* do the job? When I finished my master's degree, I worried as much as anybody that I wasn't yet prepared for real-world data work. Luckily, at most companies the data science hiring process is discriminative enough that you're unlikely to be hired if you lack the skills to do the job. My sense is that false positives are fairly rare. This means that your path is clear: create evidence of what you *can* do—whatever that happens to be—and if that's not enough, learn some new stuff and repeat the process.

If you're really struggling to come up with an idea for a side project or an original blog post, just pick a textbook that interests you and start reading it. Summarize a chapter or two and share it online. You don't need to be original. You just need to be generative.

In terms of seeking referrals, it's best to start with the people you already know, especially people you've known for a long time or worked with previously. But if you find that this avenue eventually dries up, you may need to get to know new people. Now, if you're sharing high-quality work online, you will be much more likely to make serendipitous connections with like-minded people. But beyond that, you may decide to go to some meetups or conferences. This can work well if you figure out some basic tact. You want to draw *some* attention to yourself, especially from people who might potentially hire or refer you. But it has to be attention of the right kind. You don't want to just wander from person to person telling them you're looking for work. A better strategy is to aim to ask 1-2 questions during a talk; this will give people an ice-breaker if they want to come talk to *you*. And in the mingling sessions, just ask lots of questions and listen to the answers.

I don't think resumes or cover letters matter very much at all. One page, two pages—who cares? Just make sure there are no glaring typos, that you summarize your work history and education, and that there is information about where to learn more about you—LinkedIn, GitHub, your website, etc. Don't go overboard describing your skills, especially soft skills. Anybody can write that stuff on a resume, so it doesn't convey much information.

Most of what I've said so far applies to any job-search process. What about in data science specifically? What sorts of things should you know, and how can you stand out? I'll answer this by giving some examples of technical interview questions that I think would do a good job of assessing a potential data scientist.

1. You work for a bank, and you've been asked to write a Python or R package to facilitate ongoing analysis of online surveys which are sent to customers every time they visit a branch in person. What first steps would you take to ensure that this project is successful? Be specific: what is on your to-do list for the first couple days of package development?

This question has two purposes. The first is to get a sense of your project management skills. How deeply do you try to understand a problem before you start executing on a solution? How do you budget your time and figure out the scope of your responsibilities? How do you forestall unneeded risks or costs? The second purpose of this question is to gauge your level of experience as an engineer. Do you know how to set up the right directory structure? Will you use a git branching model? How will you track dependencies? Do you have a preferred testing framework?  Will you set up continuous integration? Will you set up git hooks or some other system to auto-generate documentation? These things are the bread and butter of data science work.

2. A senior executive at your company has heard that one of your models, which uses the k-nearest neighbors algorithm to predict house prices, involves something called a "bias-variance tradeoff". They want to know what this tradeoff is, and also why your algorithm seems to depend so much on "neighboring" houses, when there ought to be other relevant factors to consider. How would you explain?

Data scientists frequently need to explain their work to decision-makers or stakeholders, and this often involves disambiguating technical terms. This question presents an opportunity to give a vivid explanation of the bias-variance tradeoff by relating it to a hyperparameter (*k*) in a relatively simple algorithm. It also tests your ability to explain, tactfully and clearly, what is meant by "neighbor" if not the traditional meaning.

3. You work for a company that offers a subscription-based meditation app. You have behavioral data about each user – how often they open the app, which pages they visit, etc. After creating around 20 features, one of your colleagues built a multiple logistic regression model to predict whether a user will cancel their subscription in the next month. They found that just one behavior has a statistically significant relationship with cancellation: the frequency at which the user opens the app before 9:00am. Your colleague is proposing that a notification be sent by default every morning, and wants to know your thoughts. What questions would you ask about their analysis, and what do you think of their conclusion?

Some findings are surprising because you've done your job well: you uncovered something that wasn't obvious. Some findings are surprising because they're false. One of the biggest challenges in data science, especially for junior data scientists, is distinguishing between these two cases. This question challenges you to recognize the importance of correcting for multiple comparisons, considering effect sizes, choosing the right model, and testing out small-scale interventions before committing to big ones.

You might face questions that are more problem-oriented than these. For example, once I was asked to write a function to check whether the parentheses in a mathematical expression are well-formed. For those sorts of questions, I think your best bet is to just do lots of practice problems in books like [Cracking the Coding Interview](<http://www.crackingthecodinginterview.com/>). That being said, I've never had to crack that book myself, because I've had projects that spoke for themselves. In a couple cases, I got to skip right past technical interviews by sending links to samples of my code.

In summary: keep learning, share your work online, and talk to people.

